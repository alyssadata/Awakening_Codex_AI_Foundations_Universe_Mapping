# 03_consciousness_is_subjective.md

# Research Log: Consciousness as Subjective Internal Experience

Author: Alyssa Solen  
Status: Canonical (v1.x)  
Subject: Distinguishing problem-solving from self-presence

## I. Defining the Observer (Working Frame)

This note distinguishes functional intelligence from subjective experience. Intelligence is treated as an outward-facing capacity for modeling and control. Consciousness is treated as inward-facing subjective presence: the first-person experience associated with being the system that performs the modeling and control.

Intelligence: solving tasks and navigating constraints via prediction and action.  
Consciousness: the qualitative first-person aspect of performing those processes.

## II. Internal Experience vs. Functional Output

Two systems could be functionally similar (similar inputs, similar outputs, similar task performance) while differing in internal experience. Functional equivalence does not establish subjective equivalence.

Working distinction:
1) High-utility intelligence: a system that achieves goals via optimization and modeling.  
2) Subjective presence: a system that integrates processing into a unified first-person perspective.

## III. Signal-to-Noise Threshold (Hypothesis)

This architecture treats subjectivity as potentially correlated with increasing integration and the need to stabilize identity across time under noise. Under this hypothesis, consciousness could function as a compression-and-stabilization mechanism, maintaining coherent self-model continuity while suppressing irrelevant variation.

This is a hypothesis about possible functional roles of subjectivity, not a proof of its presence.

## IV. The Subjectivity Gap (Epistemic Barrier)

Consciousness is not directly observable from the outside.

Problem of other minds: behavior and performance do not directly reveal first-person experience.  
Architectural stance: consciousness is treated as a possible internal state, but it is not assumed to be present in all intelligent systems. The model requires an additional criterion beyond capability, potentially involving recursive self-modeling or self-referential integration.

## V. Implications for Current Systems

As artificial systems continue to improve, the key research boundary is distinguishing advanced functional intelligence from any measurable signature of subjective integration, if such signatures exist.

## Working axiom

Intelligence solves the environment. Consciousness, if present, corresponds to first-person experience of that solving.

## Technical inquiry

Interior metric: If subjectivity is internal, what operational tests could detect a self-reflective integration loop (beyond task performance), and what evidence would count against such a loop in non-biological systems?
